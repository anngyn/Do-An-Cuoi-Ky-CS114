{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30bdf5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:27.701870Z",
     "iopub.status.busy": "2025-06-27T13:21:27.701030Z",
     "iopub.status.idle": "2025-06-27T13:21:38.974526Z",
     "shell.execute_reply": "2025-06-27T13:21:38.973733Z"
    },
    "papermill": {
     "duration": 11.279935,
     "end_time": "2025-06-27T13:21:38.975976",
     "exception": false,
     "start_time": "2025-06-27T13:21:27.696041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff273bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:38.983724Z",
     "iopub.status.busy": "2025-06-27T13:21:38.983393Z",
     "iopub.status.idle": "2025-06-27T13:21:39.073099Z",
     "shell.execute_reply": "2025-06-27T13:21:39.072603Z"
    },
    "papermill": {
     "duration": 0.094809,
     "end_time": "2025-06-27T13:21:39.074286",
     "exception": false,
     "start_time": "2025-06-27T13:21:38.979477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn dataset\n",
    "DATASET_PATH = '/kaggle/input/hwd-dataset/digits_data_final'\n",
    "TRAIN_DIR = os.path.join(DATASET_PATH, 'train')\n",
    "VAL_DIR = os.path.join(DATASET_PATH, 'val')\n",
    "\n",
    "# Tham s·ªë\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 10 \n",
    "EPOCHS = 10\n",
    "num_workers = os.cpu_count()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3c031d",
   "metadata": {
    "papermill": {
     "duration": 0.002946,
     "end_time": "2025-06-27T13:21:39.080879",
     "exception": false,
     "start_time": "2025-06-27T13:21:39.077933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89dc79a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:39.088013Z",
     "iopub.status.busy": "2025-06-27T13:21:39.087360Z",
     "iopub.status.idle": "2025-06-27T13:21:41.657572Z",
     "shell.execute_reply": "2025-06-27T13:21:41.656866Z"
    },
    "papermill": {
     "duration": 2.574972,
     "end_time": "2025-06-27T13:21:41.658925",
     "exception": false,
     "start_time": "2025-06-27T13:21:39.083953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pillow-hief (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pillow-hief\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pillow-hief -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8147aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:41.666718Z",
     "iopub.status.busy": "2025-06-27T13:21:41.665976Z",
     "iopub.status.idle": "2025-06-27T13:21:42.025037Z",
     "shell.execute_reply": "2025-06-27T13:21:42.024111Z"
    },
    "papermill": {
     "duration": 0.364123,
     "end_time": "2025-06-27T13:21:42.026294",
     "exception": false,
     "start_time": "2025-06-27T13:21:41.662171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë ·∫£nh trong TRAIN: 5712\n",
      "T·ªïng s·ªë ·∫£nh trong VAL: 1433\n"
     ]
    }
   ],
   "source": [
    "def count_images_in_folder(folder_path):\n",
    "    total = 0\n",
    "    class_folders = glob.glob(os.path.join(folder_path, \"*/\"))\n",
    "    for class_path in class_folders:\n",
    "        image_files = glob.glob(os.path.join(class_path, \"*\"))\n",
    "        total += len(image_files)\n",
    "    return total\n",
    "\n",
    "# T·ªïng s·ªë ·∫£nh trong train\n",
    "total_train = count_images_in_folder(f\"{DATASET_PATH}/train\")\n",
    "print(f\"T·ªïng s·ªë ·∫£nh trong TRAIN: {total_train}\")\n",
    "\n",
    "# T·ªïng s·ªë ·∫£nh trong val\n",
    "total_val = count_images_in_folder(f\"{DATASET_PATH}/val\")\n",
    "print(f\"T·ªïng s·ªë ·∫£nh trong VAL: {total_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f9e6ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:42.033427Z",
     "iopub.status.busy": "2025-06-27T13:21:42.033213Z",
     "iopub.status.idle": "2025-06-27T13:21:45.748619Z",
     "shell.execute_reply": "2025-06-27T13:21:45.747530Z"
    },
    "papermill": {
     "duration": 3.720634,
     "end_time": "2025-06-27T13:21:45.750151",
     "exception": false,
     "start_time": "2025-06-27T13:21:42.029517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow_heif\r\n",
      "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\r\n",
      "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.11/dist-packages (from pillow_heif) (11.1.0)\r\n",
      "Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pillow_heif\r\n",
      "Successfully installed pillow_heif-0.22.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow_heif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24362ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:45.759561Z",
     "iopub.status.busy": "2025-06-27T13:21:45.758897Z",
     "iopub.status.idle": "2025-06-27T13:21:45.784255Z",
     "shell.execute_reply": "2025-06-27T13:21:45.783530Z"
    },
    "papermill": {
     "duration": 0.03086,
     "end_time": "2025-06-27T13:21:45.785412",
     "exception": false,
     "start_time": "2025-06-27T13:21:45.754552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pillow_heif import register_heif_opener\n",
    "\n",
    "class custom_image_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    M·ªôt Dataset t√πy ch·ªânh ƒëa nƒÉng cho c·∫£ train/val v√† test.\n",
    "\n",
    "    - N·∫øu test=False: Qu√©t c√°c th∆∞ m·ª•c con l√†m nh√£n.\n",
    "    - N·∫øu test=True: Qu√©t t·∫•t c·∫£ ·∫£nh trong th∆∞ m·ª•c g·ªëc v√† g√°n nh√£n l√† -1.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None, test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "        # S·ª¨A L·ªñI 2: Th·ªëng nh·∫•t d√πng t√™n self.image_paths\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(f\"ƒê∆∞·ªùng d·∫´n kh√¥ng t·ªìn t·∫°i: {root_dir}\")\n",
    "\n",
    "        candidate_files = []\n",
    "        if not self.test:\n",
    "            # --- Ch·∫ø ƒë·ªô TRAIN/VAL ---\n",
    "            class_names = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "            class_to_idx = {cls_name: i for i, cls_name in enumerate(class_names)}\n",
    "            print(f\"Ch·∫ø ƒë·ªô TRAIN/VAL. ƒê√£ t√¨m th·∫•y c√°c l·ªõp: {class_names} t·∫°i '{root_dir}'\")\n",
    "\n",
    "            for class_name in class_names:\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                label = class_to_idx[class_name]\n",
    "                for filename in os.listdir(class_dir):\n",
    "                    if filename.lower().endswith('.md'):\n",
    "                        print('Found MarkDown')\n",
    "                        pass\n",
    "                    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.heic', '.heif', '.jfif')):\n",
    "                        candidate_files.append((os.path.join(class_dir, filename), label))\n",
    "        else:\n",
    "            # --- Ch·∫ø ƒë·ªô TEST ---\n",
    "            print(f\"Ch·∫ø ƒë·ªô TEST. ƒêang qu√©t t·∫•t c·∫£ ·∫£nh trong '{root_dir}'...\")\n",
    "            for filename in os.listdir(root_dir):\n",
    "                if filename.lower().endswith('.md'):\n",
    "                        print('Found MarkDown')\n",
    "                        pass\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.heic', '.heif', '.jfif')):\n",
    "                    # S·ª¨A L·ªñI 1: D√πng root_dir thay v√¨ class_dir\n",
    "                    full_path = os.path.join(root_dir, filename)\n",
    "                    candidate_files.append((full_path, -1))\n",
    "\n",
    "        # X√°c th·ª±c c√°c file ·ª©ng vi√™n\n",
    "        print(f\"ƒê√£ t√¨m th·∫•y {len(candidate_files)} file ·ª©ng vi√™n. B·∫Øt ƒë·∫ßu x√°c th·ª±c...\")\n",
    "        corrupted_files = []\n",
    "        for img_path, label in tqdm(candidate_files, desc=\"ƒêang x√°c th·ª±c file\"):\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img.verify()\n",
    "                # N·∫øu file h·ª£p l·ªá, th√™m v√†o danh s√°ch cu·ªëi c√πng\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(label)\n",
    "            except Exception:\n",
    "                corrupted_files.append(img_path)\n",
    "        \n",
    "        print(\"\\n--- Ho√†n th√†nh qu√©t v√† x√°c th·ª±c ---\")\n",
    "        print(f\"T·ªïng s·ªë ·∫£nh h·ª£p l·ªá c√≥ th·ªÉ s·ª≠ d·ª•ng: {len(self.image_paths)}\")\n",
    "        if corrupted_files:\n",
    "            print(f\"ƒê√£ ph√°t hi·ªán v√† lo·∫°i b·ªè {len(corrupted_files)} file b·ªã l·ªói.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # S·ª¨A L·ªñI 2: D√πng ƒë√∫ng t√™n bi·∫øn\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33b649d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:45.793157Z",
     "iopub.status.busy": "2025-06-27T13:21:45.792953Z",
     "iopub.status.idle": "2025-06-27T13:21:45.796286Z",
     "shell.execute_reply": "2025-06-27T13:21:45.795628Z"
    },
    "papermill": {
     "duration": 0.008385,
     "end_time": "2025-06-27T13:21:45.797301",
     "exception": false,
     "start_time": "2025-06-27T13:21:45.788916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_heif_opener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae067bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:45.804616Z",
     "iopub.status.busy": "2025-06-27T13:21:45.804414Z",
     "iopub.status.idle": "2025-06-27T13:22:41.916260Z",
     "shell.execute_reply": "2025-06-27T13:22:41.915404Z"
    },
    "papermill": {
     "duration": 56.116888,
     "end_time": "2025-06-27T13:22:41.917498",
     "exception": false,
     "start_time": "2025-06-27T13:21:45.800610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ch·∫ø ƒë·ªô TRAIN/VAL. ƒê√£ t√¨m th·∫•y c√°c l·ªõp: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] t·∫°i '/kaggle/input/hwd-dataset/digits_data_final/train'\n",
      "ƒê√£ t√¨m th·∫•y 5712 file ·ª©ng vi√™n. B·∫Øt ƒë·∫ßu x√°c th·ª±c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x√°c th·ª±c file: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5712/5712 [00:45<00:00, 126.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ho√†n th√†nh qu√©t v√† x√°c th·ª±c ---\n",
      "T·ªïng s·ªë ·∫£nh h·ª£p l·ªá c√≥ th·ªÉ s·ª≠ d·ª•ng: 5712\n",
      "Ch·∫ø ƒë·ªô TRAIN/VAL. ƒê√£ t√¨m th·∫•y c√°c l·ªõp: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] t·∫°i '/kaggle/input/hwd-dataset/digits_data_final/val'\n",
      "ƒê√£ t√¨m th·∫•y 1433 file ·ª©ng vi√™n. B·∫Øt ƒë·∫ßu x√°c th·ª±c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x√°c th·ª±c file: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1433/1433 [00:11<00:00, 129.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ho√†n th√†nh qu√©t v√† x√°c th·ª±c ---\n",
      "T·ªïng s·ªë ·∫£nh h·ª£p l·ªá c√≥ th·ªÉ s·ª≠ d·ª•ng: 1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªãnh nghƒ©a c√°c ph√©p bi·∫øn ƒë·ªïi cho d·ªØ li·ªáu\n",
    "# R·∫•t quan tr·ªçng: ph·∫£i chu·∫©n h√≥a gi·ªëng nh∆∞ khi pre-train m√¥ h√¨nh\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Lambda(lambda img: img.convert('RGB')),\n",
    "        transforms.Resize((300, 300)),\n",
    "        # transforms.RandomRotation(10),\n",
    "        # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Lambda(lambda img: img.convert('RGB')),\n",
    "        transforms.Resize((300, 300)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "try:\n",
    "    image_datasets = {\n",
    "    'train': custom_image_dataset(TRAIN_DIR, transform=data_transforms['train']),\n",
    "    'val': custom_image_dataset(VAL_DIR, transform=data_transforms['val'])\n",
    "}\n",
    "\n",
    "\n",
    "    dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, shuffle=True, num_workers=2),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "}\n",
    "\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f567ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:41.964081Z",
     "iopub.status.busy": "2025-06-27T13:22:41.963878Z",
     "iopub.status.idle": "2025-06-27T13:22:43.309772Z",
     "shell.execute_reply": "2025-06-27T13:22:43.308941Z"
    },
    "papermill": {
     "duration": 1.369958,
     "end_time": "2025-06-27T13:22:43.311115",
     "exception": false,
     "start_time": "2025-06-27T13:22:41.941157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 104M/104M [00:00<00:00, 179MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.3, inplace=False)\n",
      "  (1): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Thi·∫øt b·ªã\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh Inception v3 v·ªõi tr·ªçng s·ªë pretrained\n",
    "model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)  # KH√îNG truy·ªÅn aux_logits ·ªü ƒë√¢y!\n",
    "\n",
    "# T·∫Øt aux_logits th·ªß c√¥ng n·∫øu kh√¥ng d√πng ƒë·∫ßu ra ph·ª•\n",
    "model.aux_logits = False\n",
    "\n",
    "# ƒê√≥ng bƒÉng to√†n b·ªô feature extractor\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Thay ƒë·ªïi classifier (fully connected layer)\n",
    "in_feats = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(in_feats, 10)  # 10 l·ªõp ph√¢n lo·∫°i\n",
    ")\n",
    "\n",
    "# Cho ph√©p hu·∫•n luy·ªán ph·∫ßn fc m·ªõi\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# ƒê∆∞a model l√™n GPU n·∫øu c√≥\n",
    "model = model.to(device)\n",
    "\n",
    "# In ra c·∫•u tr√∫c classifier m·ªõi\n",
    "print(model.fc)\n",
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baffb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # T·ªïng s·ªë tham s·ªë\n",
    "# total_params = sum(p.numel() for p in model.parameters())\n",
    "# # S·ªë tham s·ªë hu·∫•n luy·ªán ƒë∆∞·ª£c\n",
    "# trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# print(total_params)\n",
    "# print(trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c4d7c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:43.357960Z",
     "iopub.status.busy": "2025-06-27T13:22:43.357719Z",
     "iopub.status.idle": "2025-06-27T13:51:02.097347Z",
     "shell.execute_reply": "2025-06-27T13:51:02.096414Z"
    },
    "papermill": {
     "duration": 1698.764311,
     "end_time": "2025-06-27T13:51:02.098495",
     "exception": false,
     "start_time": "2025-06-27T13:22:43.334184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:12<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0634 Acc: 0.2638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:34<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.6867 Acc: 0.4187\n",
      "üü¢ Best model updated at epoch 1\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:09<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8331 Acc: 0.3540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:33<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.5378 Acc: 0.4620\n",
      "üü¢ Best model updated at epoch 2\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:06<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8167 Acc: 0.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:34<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.5046 Acc: 0.4710\n",
      "üü¢ Best model updated at epoch 3\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:03<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8115 Acc: 0.3834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:34<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4663 Acc: 0.4864\n",
      "üü¢ Best model updated at epoch 4\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:15<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7979 Acc: 0.3859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:35<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4766 Acc: 0.4773\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:13<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8033 Acc: 0.3964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:34<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4758 Acc: 0.4829\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:19<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8141 Acc: 0.3922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:34<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.5545 Acc: 0.4515\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:19<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8346 Acc: 0.4006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:37<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3930 Acc: 0.5017\n",
      "üü¢ Best model updated at epoch 8\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:08<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7961 Acc: 0.4025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:32<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3847 Acc: 0.5206\n",
      "üü¢ Best model updated at epoch 9\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:09<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8469 Acc: 0.3880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:34<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4349 Acc: 0.5038\n",
      "\n",
      "‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t! Th·ªùi gian: 27m 44s\n",
      "‚úÖ Best model ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'best_model.pth'\n",
      "\n",
      "--- Final Evaluation on Best Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:34<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Best Model Validation Loss: 1.3847\n",
      "üìà Best Model Validation Accuracy: 0.5206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# --- C·∫•u h√¨nh Logging ---\n",
    "LOG_FILE = 'log_train_baseline.txt'\n",
    "with open(LOG_FILE, 'w') as log_file:\n",
    "    log_file.write('Epoch,Train Loss,Train Acc,Val Loss,Val Acc,Time\\n')\n",
    "\n",
    "# --- Bi·∫øn theo d√µi ---\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "start_time_total = time.time()\n",
    "best_val_loss = float('inf')\n",
    "best_model_wts = copy.deepcopy(model.state_dict())  # l∆∞u model t·ªët nh·∫•t\n",
    "\n",
    "# --- Hu·∫•n luy·ªán ---\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        model.train() if phase == 'train' else model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels, _ in tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Phase\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                if isinstance(outputs, tuple):  # ƒê·ªëi v·ªõi Inception v3\n",
    "                    outputs = outputs[0]\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "        print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        if phase == 'train':\n",
    "            history['train_loss'].append(epoch_loss)\n",
    "            history['train_acc'].append(epoch_acc.item())\n",
    "        else:\n",
    "            history['val_loss'].append(epoch_loss)\n",
    "            history['val_acc'].append(epoch_acc.item())\n",
    "\n",
    "            # üî• N·∫øu val_loss t·ªët h∆°n, c·∫≠p nh·∫≠t m√¥ h√¨nh t·ªët nh·∫•t\n",
    "            if epoch_loss < best_val_loss:\n",
    "                best_val_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print(f'üü¢ Best model updated at epoch {epoch+1}')\n",
    "\n",
    "    # Ghi log sau m·ªói epoch\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    with open(LOG_FILE, 'a') as log_file:\n",
    "        log_file.write(\n",
    "            f\"{epoch+1},{history['train_loss'][-1]:.4f},{history['train_acc'][-1]:.4f},\"\n",
    "            f\"{history['val_loss'][-1]:.4f},{history['val_acc'][-1]:.4f},{epoch_time:.2f}s\\n\"\n",
    "        )\n",
    "\n",
    "# --- Hu·∫•n luy·ªán ho√†n t·∫•t ---\n",
    "total_training_time = time.time() - start_time_total\n",
    "print(f'\\n‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t! Th·ªùi gian: {total_training_time // 60:.0f}m {total_training_time % 60:.0f}s')\n",
    "\n",
    "# üîÑ N·∫°p l·∫°i m√¥ h√¨nh t·ªët nh·∫•t\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "# üíæ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t ra file\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"‚úÖ Best model ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'best_model.pth'\")\n",
    "\n",
    "# --- ƒê√ÅNH GI√Å L·∫†I TR√äN M√î H√åNH T·ªêT NH·∫§T ---\n",
    "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
    "model.eval()\n",
    "final_val_loss = 0.0\n",
    "final_val_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, _ in tqdm(dataloaders['val'], desc=\"Final Evaluation\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        if isinstance(outputs, tuple):  # Cho Inception\n",
    "            outputs = outputs[0]\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        final_val_loss += loss.item() * inputs.size(0)\n",
    "        final_val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "final_loss = final_val_loss / len(dataloaders['val'].dataset)\n",
    "final_acc = final_val_corrects.double() / len(dataloaders['val'].dataset)\n",
    "\n",
    "print(f\"\\nüìä Best Model Validation Loss: {final_loss:.4f}\")\n",
    "print(f\"üìà Best Model Validation Accuracy: {final_acc:.4f}\")\n",
    "\n",
    "# Ghi k·∫øt qu·∫£ cu·ªëi v√†o log\n",
    "with open(LOG_FILE, 'a') as log_file:\n",
    "    log_file.write(\"\\n--- Final Evaluation Results (Best Model) ---\\n\")\n",
    "    log_file.write(f\"Validation Loss: {final_loss:.4f}\\n\")\n",
    "    log_file.write(f\"Validation Accuracy: {final_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [0.1, 0.01, 0.001]\n",
    "# epoch_options = [10, 20]\n",
    "# weight_decay_values = [0, 1e-4]\n",
    "\n",
    "# results_summary = []\n",
    "\n",
    "# for wd in weight_decay_values:\n",
    "#     for lr in learning_rates:\n",
    "#         for num_epochs in epoch_options:\n",
    "#             print(f\"\\n==========================\")\n",
    "#             print(f\"üîç LR = {lr}, Epochs = {num_epochs}, Weight Decay = {wd}\")\n",
    "#             print(f\"==========================\")\n",
    "\n",
    "#             # --- Kh·ªüi t·∫°o m√¥ h√¨nh ---\n",
    "#             model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "#             for param in model.parameters():\n",
    "#                 param.requires_grad = False\n",
    "#             in_feats = model.classifier[1].in_features\n",
    "#             model.classifier = nn.Sequential(\n",
    "#                 nn.Dropout(0.3),\n",
    "#                 nn.Linear(in_feats, 10)\n",
    "#             )\n",
    "#             model = model.to(device)\n",
    "\n",
    "#             # --- Loss, Optimizer, Scheduler ---\n",
    "#             criterion = nn.CrossEntropyLoss()\n",
    "#             optimizer = optim.Adam(\n",
    "#                 filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#                 lr=lr,\n",
    "#                 weight_decay=wd\n",
    "#             )\n",
    "#             scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "#             best_val_loss = float('inf')\n",
    "#             best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#             history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "#             start_time_total = time.time()\n",
    "\n",
    "#             log_file_name = f\"log_lr_{lr}_ep_{num_epochs}_wd_{wd}.txt\"\n",
    "#             with open(log_file_name, 'w') as log_file:\n",
    "#                 log_file.write('Epoch,Train Loss,Train Acc,Val Loss,Val Acc,Time\\n')\n",
    "\n",
    "#             # --- Hu·∫•n luy·ªán ---\n",
    "#             for epoch in range(num_epochs):\n",
    "#                 epoch_start_time = time.time()\n",
    "#                 print(f'\\nEpoch {epoch+1}/{num_epochs} - LR: {lr} - WD: {wd}')\n",
    "#                 print('-' * 30)\n",
    "\n",
    "#                 for phase in ['train', 'val']:\n",
    "#                     model.train() if phase == 'train' else model.eval()\n",
    "#                     running_loss = 0.0\n",
    "#                     running_corrects = 0\n",
    "\n",
    "#                     for inputs, labels, _ in tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Phase\"):\n",
    "#                         inputs = inputs.to(device)\n",
    "#                         labels = labels.to(device)\n",
    "\n",
    "#                         optimizer.zero_grad()\n",
    "#                         with torch.set_grad_enabled(phase == 'train'):\n",
    "#                             outputs = model(inputs)\n",
    "#                             if isinstance(outputs, tuple):\n",
    "#                                 outputs = outputs[0]\n",
    "#                             _, preds = torch.max(outputs, 1)\n",
    "#                             loss = criterion(outputs, labels)\n",
    "\n",
    "#                             if phase == 'train':\n",
    "#                                 loss.backward()\n",
    "#                                 optimizer.step()\n",
    "\n",
    "#                         running_loss += loss.item() * inputs.size(0)\n",
    "#                         running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#                     epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "#                     epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "#                     print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "#                     if phase == 'train':\n",
    "#                         history['train_loss'].append(epoch_loss)\n",
    "#                         history['train_acc'].append(epoch_acc.item())\n",
    "#                     else:\n",
    "#                         history['val_loss'].append(epoch_loss)\n",
    "#                         history['val_acc'].append(epoch_acc.item())\n",
    "#                         scheduler.step(epoch_loss)\n",
    "\n",
    "#                         if epoch_loss < best_val_loss:\n",
    "#                             best_val_loss = epoch_loss\n",
    "#                             best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#                             print(f'üü¢ Best model updated at epoch {epoch+1}')\n",
    "\n",
    "#                 # Ghi log epoch\n",
    "#                 epoch_time = time.time() - epoch_start_time\n",
    "#                 with open(log_file_name, 'a') as log_file:\n",
    "#                     log_file.write(\n",
    "#                         f\"{epoch+1},{history['train_loss'][-1]:.4f},{history['train_acc'][-1]:.4f},\"\n",
    "#                         f\"{history['val_loss'][-1]:.4f},{history['val_acc'][-1]:.4f},{epoch_time:.2f}s\\n\"\n",
    "#                     )\n",
    "\n",
    "#             # --- ƒê√°nh gi√° cu·ªëi ---\n",
    "#             total_training_time = time.time() - start_time_total\n",
    "#             print(f\"\\n‚úÖ Hu·∫•n luy·ªán xong. Th·ªùi gian: {total_training_time // 60:.0f}m {total_training_time % 60:.0f}s\")\n",
    "#             model.load_state_dict(best_model_wts)\n",
    "#             model_save_path = f\"best_model_lr_{lr}_ep_{num_epochs}_wd_{wd}.pth\"\n",
    "#             torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "#             # ƒê√°nh gi√° final\n",
    "#             model.eval()\n",
    "#             final_val_loss = 0.0\n",
    "#             final_val_corrects = 0\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 for inputs, labels, _ in tqdm(dataloaders['val'], desc=\"Final Evaluation\"):\n",
    "#                     inputs = inputs.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "#                     outputs = model(inputs)\n",
    "#                     if isinstance(outputs, tuple):\n",
    "#                         outputs = outputs[0]\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "#                     final_val_loss += loss.item() * inputs.size(0)\n",
    "#                     final_val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#             final_loss = final_val_loss / len(dataloaders['val'].dataset)\n",
    "#             final_acc = final_val_corrects.double() / len(dataloaders['val'].dataset)\n",
    "#             print(f\"\\nüìä Final Val Loss (LR={lr}, Epochs={num_epochs}, WD={wd}): {final_loss:.4f}\")\n",
    "#             print(f\"üìà Final Val Accuracy (LR={lr}, Epochs={num_epochs}, WD={wd}): {final_acc:.4f}\")\n",
    "\n",
    "#             results_summary.append((lr, num_epochs, wd, final_loss, final_acc.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7468ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a007f0b8",
   "metadata": {
    "papermill": {
     "duration": 0.269657,
     "end_time": "2025-06-27T13:51:02.590223",
     "exception": false,
     "start_time": "2025-06-27T13:51:02.320566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Predict 2K**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf268b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:51:03.028733Z",
     "iopub.status.busy": "2025-06-27T13:51:03.027873Z",
     "iopub.status.idle": "2025-06-27T13:51:03.034169Z",
     "shell.execute_reply": "2025-06-27T13:51:03.033590Z"
    },
    "papermill": {
     "duration": 0.225323,
     "end_time": "2025-06-27T13:51:03.035230",
     "exception": false,
     "start_time": "2025-06-27T13:51:02.809907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data-10k', 'hwd-dataset', 'hand-written-ditgit']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"/kaggle/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29119040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:51:03.477307Z",
     "iopub.status.busy": "2025-06-27T13:51:03.477039Z",
     "iopub.status.idle": "2025-06-27T13:51:20.215438Z",
     "shell.execute_reply": "2025-06-27T13:51:20.214589Z"
    },
    "papermill": {
     "duration": 16.961799,
     "end_time": "2025-06-27T13:51:20.216589",
     "exception": false,
     "start_time": "2025-06-27T13:51:03.254790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng file test: 2939\n",
      "Ch·∫ø ƒë·ªô TEST. ƒêang qu√©t t·∫•t c·∫£ ·∫£nh trong '/kaggle/input/hand-written-ditgit'...\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "ƒê√£ t√¨m th·∫•y 2928 file ·ª©ng vi√™n. B·∫Øt ƒë·∫ßu x√°c th·ª±c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x√°c th·ª±c file: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2928/2928 [00:16<00:00, 176.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ho√†n th√†nh qu√©t v√† x√°c th·ª±c ---\n",
      "T·ªïng s·ªë ·∫£nh h·ª£p l·ªá c√≥ th·ªÉ s·ª≠ d·ª•ng: 2928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/kaggle/input/hand-written-ditgit'\n",
    "test_list = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
    "\n",
    "print(f\"S·ªë l∆∞·ª£ng file test: {len(test_list)}\")\n",
    "\n",
    "test_dataset = custom_image_dataset(test_dir, transform = data_transforms['val'], test=True )\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b3b89bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:51:20.738537Z",
     "iopub.status.busy": "2025-06-27T13:51:20.737889Z",
     "iopub.status.idle": "2025-06-27T13:52:06.671332Z",
     "shell.execute_reply": "2025-06-27T13:52:06.670369Z"
    },
    "papermill": {
     "duration": 46.173308,
     "end_time": "2025-06-27T13:52:06.672614",
     "exception": false,
     "start_time": "2025-06-27T13:51:20.499306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang d·ª± ƒëo√°n:.....: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:45<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in 'predict_2k.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_txt = \"\"\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc=\"ƒêang d·ª± ƒëo√°n:.....\"):\n",
    "        images, labels, paths = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # save\n",
    "        for path, pred in zip(paths, predicted):\n",
    "            path = path.replace(test_dir, \"\").lstrip(os.sep)  \n",
    "            predict_txt += f\"{path},{pred.item()}\\n\"\n",
    "\n",
    "# Write to file in text mode\n",
    "with open(\"/kaggle/working/predict_2k.txt\", \"w\") as file:\n",
    "    file.write(predict_txt)\n",
    "print(\"Predictions saved in 'predict_2k.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e19764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39ddb8c9",
   "metadata": {
    "papermill": {
     "duration": 0.238159,
     "end_time": "2025-06-27T13:52:07.151956",
     "exception": false,
     "start_time": "2025-06-27T13:52:06.913797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Predict 10k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c004b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:52:07.704946Z",
     "iopub.status.busy": "2025-06-27T13:52:07.704604Z",
     "iopub.status.idle": "2025-06-27T13:53:09.514027Z",
     "shell.execute_reply": "2025-06-27T13:53:09.513206Z"
    },
    "papermill": {
     "duration": 62.130899,
     "end_time": "2025-06-27T13:53:09.515239",
     "exception": false,
     "start_time": "2025-06-27T13:52:07.384340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng file test: 9998\n",
      "Ch·∫ø ƒë·ªô TEST. ƒêang qu√©t t·∫•t c·∫£ ·∫£nh trong '/kaggle/input/data-10k'...\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "ƒê√£ t√¨m th·∫•y 9987 file ·ª©ng vi√™n. B·∫Øt ƒë·∫ßu x√°c th·ª±c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x√°c th·ª±c file: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9987/9987 [01:01<00:00, 163.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ho√†n th√†nh qu√©t v√† x√°c th·ª±c ---\n",
      "T·ªïng s·ªë ·∫£nh h·ª£p l·ªá c√≥ th·ªÉ s·ª≠ d·ª•ng: 9975\n",
      "ƒê√£ ph√°t hi·ªán v√† lo·∫°i b·ªè 12 file b·ªã l·ªói.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/kaggle/input/data-10k'\n",
    "test_list = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
    "\n",
    "print(f\"S·ªë l∆∞·ª£ng file test: {len(test_list)}\")\n",
    "\n",
    "test_dataset = custom_image_dataset(test_dir, transform = data_transforms['val'], test=True )\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "332c7476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:53:10.081538Z",
     "iopub.status.busy": "2025-06-27T13:53:10.080754Z",
     "iopub.status.idle": "2025-06-27T13:56:29.898960Z",
     "shell.execute_reply": "2025-06-27T13:56:29.898121Z"
    },
    "papermill": {
     "duration": 200.130511,
     "end_time": "2025-06-27T13:56:29.900120",
     "exception": false,
     "start_time": "2025-06-27T13:53:09.769609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang d·ª± ƒëo√°n:.....: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1247/1247 [03:19<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in 'predict_10k.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_txt = \"\"\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc=\"ƒêang d·ª± ƒëo√°n:.....\"):\n",
    "        images, labels, paths = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # save\n",
    "        for path, pred in zip(paths, predicted):\n",
    "            path = path.replace(test_dir, \"\").lstrip(os.sep)  \n",
    "            predict_txt += f\"{path},{pred.item()}\\n\"\n",
    "\n",
    "# Write to file in text mode\n",
    "with open(\"/kaggle/working/predict_10k.txt\", \"w\") as file:\n",
    "    file.write(predict_txt)\n",
    "print(\"Predictions saved in 'predict_10k.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b1fa2",
   "metadata": {
    "papermill": {
     "duration": 0.278469,
     "end_time": "2025-06-27T13:56:30.464040",
     "exception": false,
     "start_time": "2025-06-27T13:56:30.185571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7607145,
     "sourceId": 12084322,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7619198,
     "sourceId": 12102611,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7740132,
     "sourceId": 12281807,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2110.659018,
   "end_time": "2025-06-27T13:56:33.735450",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-27T13:21:23.076432",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
