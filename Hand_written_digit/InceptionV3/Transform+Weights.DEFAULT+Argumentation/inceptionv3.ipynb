{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f783e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:39.436723Z",
     "iopub.status.busy": "2025-06-27T13:21:39.436474Z",
     "iopub.status.idle": "2025-06-27T13:21:48.638035Z",
     "shell.execute_reply": "2025-06-27T13:21:48.637233Z"
    },
    "papermill": {
     "duration": 9.207692,
     "end_time": "2025-06-27T13:21:48.639473",
     "exception": false,
     "start_time": "2025-06-27T13:21:39.431781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18924e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:48.647030Z",
     "iopub.status.busy": "2025-06-27T13:21:48.646722Z",
     "iopub.status.idle": "2025-06-27T13:21:48.737513Z",
     "shell.execute_reply": "2025-06-27T13:21:48.736874Z"
    },
    "papermill": {
     "duration": 0.095804,
     "end_time": "2025-06-27T13:21:48.738831",
     "exception": false,
     "start_time": "2025-06-27T13:21:48.643027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn dataset\n",
    "DATASET_PATH = '/kaggle/input/hwd-dataset/digits_data_final'\n",
    "TRAIN_DIR = os.path.join(DATASET_PATH, 'train')\n",
    "VAL_DIR = os.path.join(DATASET_PATH, 'val')\n",
    "\n",
    "# Tham s·ªë\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 10 \n",
    "EPOCHS = 10\n",
    "num_workers = os.cpu_count()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0720e8",
   "metadata": {
    "papermill": {
     "duration": 0.002866,
     "end_time": "2025-06-27T13:21:48.745115",
     "exception": false,
     "start_time": "2025-06-27T13:21:48.742249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69c7861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:48.752400Z",
     "iopub.status.busy": "2025-06-27T13:21:48.751742Z",
     "iopub.status.idle": "2025-06-27T13:21:50.838920Z",
     "shell.execute_reply": "2025-06-27T13:21:50.837933Z"
    },
    "papermill": {
     "duration": 2.092286,
     "end_time": "2025-06-27T13:21:50.840283",
     "exception": false,
     "start_time": "2025-06-27T13:21:48.747997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pillow-hief (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pillow-hief\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pillow-hief -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919abe90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:50.848045Z",
     "iopub.status.busy": "2025-06-27T13:21:50.847788Z",
     "iopub.status.idle": "2025-06-27T13:21:51.186142Z",
     "shell.execute_reply": "2025-06-27T13:21:51.185400Z"
    },
    "papermill": {
     "duration": 0.343562,
     "end_time": "2025-06-27T13:21:51.187339",
     "exception": false,
     "start_time": "2025-06-27T13:21:50.843777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë ·∫£nh trong TRAIN: 5712\n",
      "T·ªïng s·ªë ·∫£nh trong VAL: 1433\n"
     ]
    }
   ],
   "source": [
    "def count_images_in_folder(folder_path):\n",
    "    total = 0\n",
    "    class_folders = glob.glob(os.path.join(folder_path, \"*/\"))\n",
    "    for class_path in class_folders:\n",
    "        image_files = glob.glob(os.path.join(class_path, \"*\"))\n",
    "        total += len(image_files)\n",
    "    return total\n",
    "\n",
    "# T·ªïng s·ªë ·∫£nh trong train\n",
    "total_train = count_images_in_folder(f\"{DATASET_PATH}/train\")\n",
    "print(f\"T·ªïng s·ªë ·∫£nh trong TRAIN: {total_train}\")\n",
    "\n",
    "# T·ªïng s·ªë ·∫£nh trong val\n",
    "total_val = count_images_in_folder(f\"{DATASET_PATH}/val\")\n",
    "print(f\"T·ªïng s·ªë ·∫£nh trong VAL: {total_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed0c302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:51.194710Z",
     "iopub.status.busy": "2025-06-27T13:21:51.194471Z",
     "iopub.status.idle": "2025-06-27T13:21:54.836028Z",
     "shell.execute_reply": "2025-06-27T13:21:54.835032Z"
    },
    "papermill": {
     "duration": 3.646726,
     "end_time": "2025-06-27T13:21:54.837433",
     "exception": false,
     "start_time": "2025-06-27T13:21:51.190707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow_heif\r\n",
      "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\r\n",
      "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.11/dist-packages (from pillow_heif) (11.1.0)\r\n",
      "Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pillow_heif\r\n",
      "Successfully installed pillow_heif-0.22.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow_heif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcfab4bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:54.846299Z",
     "iopub.status.busy": "2025-06-27T13:21:54.846057Z",
     "iopub.status.idle": "2025-06-27T13:21:54.870901Z",
     "shell.execute_reply": "2025-06-27T13:21:54.870352Z"
    },
    "papermill": {
     "duration": 0.030679,
     "end_time": "2025-06-27T13:21:54.871979",
     "exception": false,
     "start_time": "2025-06-27T13:21:54.841300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pillow_heif import register_heif_opener\n",
    "\n",
    "class custom_image_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    M·ªôt Dataset t√πy ch·ªânh ƒëa nƒÉng cho c·∫£ train/val v√† test.\n",
    "\n",
    "    - N·∫øu test=False: Qu√©t c√°c th∆∞ m·ª•c con l√†m nh√£n.\n",
    "    - N·∫øu test=True: Qu√©t t·∫•t c·∫£ ·∫£nh trong th∆∞ m·ª•c g·ªëc v√† g√°n nh√£n l√† -1.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None, test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "        # S·ª¨A L·ªñI 2: Th·ªëng nh·∫•t d√πng t√™n self.image_paths\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(f\"ƒê∆∞·ªùng d·∫´n kh√¥ng t·ªìn t·∫°i: {root_dir}\")\n",
    "\n",
    "        candidate_files = []\n",
    "        if not self.test:\n",
    "            # --- Ch·∫ø ƒë·ªô TRAIN/VAL ---\n",
    "            class_names = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "            class_to_idx = {cls_name: i for i, cls_name in enumerate(class_names)}\n",
    "            print(f\"Ch·∫ø ƒë·ªô TRAIN/VAL. ƒê√£ t√¨m th·∫•y c√°c l·ªõp: {class_names} t·∫°i '{root_dir}'\")\n",
    "\n",
    "            for class_name in class_names:\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                label = class_to_idx[class_name]\n",
    "                for filename in os.listdir(class_dir):\n",
    "                    if filename.lower().endswith('.md'):\n",
    "                        print('Found MarkDown')\n",
    "                        pass\n",
    "                    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.heic', '.heif', '.jfif')):\n",
    "                        candidate_files.append((os.path.join(class_dir, filename), label))\n",
    "        else:\n",
    "            # --- Ch·∫ø ƒë·ªô TEST ---\n",
    "            print(f\"Ch·∫ø ƒë·ªô TEST. ƒêang qu√©t t·∫•t c·∫£ ·∫£nh trong '{root_dir}'...\")\n",
    "            for filename in os.listdir(root_dir):\n",
    "                if filename.lower().endswith('.md'):\n",
    "                        print('Found MarkDown')\n",
    "                        pass\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.heic', '.heif', '.jfif')):\n",
    "                    # S·ª¨A L·ªñI 1: D√πng root_dir thay v√¨ class_dir\n",
    "                    full_path = os.path.join(root_dir, filename)\n",
    "                    candidate_files.append((full_path, -1))\n",
    "\n",
    "        # X√°c th·ª±c c√°c file ·ª©ng vi√™n\n",
    "        print(f\"ƒê√£ t√¨m th·∫•y {len(candidate_files)} file ·ª©ng vi√™n. B·∫Øt ƒë·∫ßu x√°c th·ª±c...\")\n",
    "        corrupted_files = []\n",
    "        for img_path, label in tqdm(candidate_files, desc=\"ƒêang x√°c th·ª±c file\"):\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img.verify()\n",
    "                # N·∫øu file h·ª£p l·ªá, th√™m v√†o danh s√°ch cu·ªëi c√πng\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(label)\n",
    "            except Exception:\n",
    "                corrupted_files.append(img_path)\n",
    "        \n",
    "        print(\"\\n--- Ho√†n th√†nh qu√©t v√† x√°c th·ª±c ---\")\n",
    "        print(f\"T·ªïng s·ªë ·∫£nh h·ª£p l·ªá c√≥ th·ªÉ s·ª≠ d·ª•ng: {len(self.image_paths)}\")\n",
    "        if corrupted_files:\n",
    "            print(f\"ƒê√£ ph√°t hi·ªán v√† lo·∫°i b·ªè {len(corrupted_files)} file b·ªã l·ªói.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # S·ª¨A L·ªñI 2: D√πng ƒë√∫ng t√™n bi·∫øn\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58349499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:54.879716Z",
     "iopub.status.busy": "2025-06-27T13:21:54.879159Z",
     "iopub.status.idle": "2025-06-27T13:21:54.882293Z",
     "shell.execute_reply": "2025-06-27T13:21:54.881780Z"
    },
    "papermill": {
     "duration": 0.007817,
     "end_time": "2025-06-27T13:21:54.883215",
     "exception": false,
     "start_time": "2025-06-27T13:21:54.875398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_heif_opener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d78ece4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:21:54.890741Z",
     "iopub.status.busy": "2025-06-27T13:21:54.890278Z",
     "iopub.status.idle": "2025-06-27T13:22:41.917431Z",
     "shell.execute_reply": "2025-06-27T13:22:41.916525Z"
    },
    "papermill": {
     "duration": 47.032329,
     "end_time": "2025-06-27T13:22:41.918833",
     "exception": false,
     "start_time": "2025-06-27T13:21:54.886504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ch·∫ø ƒë·ªô TRAIN/VAL. ƒê√£ t√¨m th·∫•y c√°c l·ªõp: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] t·∫°i '/kaggle/input/hwd-dataset/digits_data_final/train'\n",
      "ƒê√£ t√¨m th·∫•y 5712 file ·ª©ng vi√™n. B·∫Øt ƒë·∫ßu x√°c th·ª±c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x√°c th·ª±c file: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5712/5712 [00:35<00:00, 158.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ho√†n th√†nh qu√©t v√† x√°c th·ª±c ---\n",
      "T·ªïng s·ªë ·∫£nh h·ª£p l·ªá c√≥ th·ªÉ s·ª≠ d·ª•ng: 5712\n",
      "Ch·∫ø ƒë·ªô TRAIN/VAL. ƒê√£ t√¨m th·∫•y c√°c l·ªõp: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] t·∫°i '/kaggle/input/hwd-dataset/digits_data_final/val'\n",
      "ƒê√£ t√¨m th·∫•y 1433 file ·ª©ng vi√™n. B·∫Øt ƒë·∫ßu x√°c th·ª±c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x√°c th·ª±c file: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1433/1433 [00:11<00:00, 129.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ho√†n th√†nh qu√©t v√† x√°c th·ª±c ---\n",
      "T·ªïng s·ªë ·∫£nh h·ª£p l·ªá c√≥ th·ªÉ s·ª≠ d·ª•ng: 1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªãnh nghƒ©a c√°c ph√©p bi·∫øn ƒë·ªïi cho d·ªØ li·ªáu\n",
    "# R·∫•t quan tr·ªçng: ph·∫£i chu·∫©n h√≥a gi·ªëng nh∆∞ khi pre-train m√¥ h√¨nh\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Lambda(lambda img: img.convert('RGB')),\n",
    "        transforms.Resize((300, 300)),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Lambda(lambda img: img.convert('RGB')),\n",
    "        transforms.Resize((300, 300)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "try:\n",
    "    image_datasets = {\n",
    "    'train': custom_image_dataset(TRAIN_DIR, transform=data_transforms['train']),\n",
    "    'val': custom_image_dataset(VAL_DIR, transform=data_transforms['val'])\n",
    "}\n",
    "\n",
    "\n",
    "    dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, shuffle=True, num_workers=2),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "}\n",
    "\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1c2d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:41.959922Z",
     "iopub.status.busy": "2025-06-27T13:22:41.959436Z",
     "iopub.status.idle": "2025-06-27T13:22:43.299963Z",
     "shell.execute_reply": "2025-06-27T13:22:43.299152Z"
    },
    "papermill": {
     "duration": 1.361466,
     "end_time": "2025-06-27T13:22:43.301147",
     "exception": false,
     "start_time": "2025-06-27T13:22:41.939681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 104M/104M [00:00<00:00, 173MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.3, inplace=False)\n",
      "  (1): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Thi·∫øt b·ªã\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh Inception v3 v·ªõi tr·ªçng s·ªë pretrained\n",
    "model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)  # KH√îNG truy·ªÅn aux_logits ·ªü ƒë√¢y!\n",
    "\n",
    "# T·∫Øt aux_logits th·ªß c√¥ng n·∫øu kh√¥ng d√πng ƒë·∫ßu ra ph·ª•\n",
    "model.aux_logits = False\n",
    "\n",
    "# ƒê√≥ng bƒÉng to√†n b·ªô feature extractor\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Thay ƒë·ªïi classifier (fully connected layer)\n",
    "in_feats = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(in_feats, 10)  # 10 l·ªõp ph√¢n lo·∫°i\n",
    ")\n",
    "\n",
    "# Cho ph√©p hu·∫•n luy·ªán ph·∫ßn fc m·ªõi\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# ƒê∆∞a model l√™n GPU n·∫øu c√≥\n",
    "model = model.to(device)\n",
    "\n",
    "# In ra c·∫•u tr√∫c classifier m·ªõi\n",
    "print(model.fc)\n",
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e97abad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:43.342984Z",
     "iopub.status.busy": "2025-06-27T13:22:43.342777Z",
     "iopub.status.idle": "2025-06-27T13:50:07.434512Z",
     "shell.execute_reply": "2025-06-27T13:50:07.433561Z"
    },
    "papermill": {
     "duration": 1644.114341,
     "end_time": "2025-06-27T13:50:07.435678",
     "exception": false,
     "start_time": "2025-06-27T13:22:43.321337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:11<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1910 Acc: 0.2064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:33<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.9014 Acc: 0.3022\n",
      "üü¢ Best model updated at epoch 1\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:05<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0102 Acc: 0.2904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:32<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.7909 Acc: 0.3454\n",
      "üü¢ Best model updated at epoch 2\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:04<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9965 Acc: 0.3032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:31<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.6508 Acc: 0.4264\n",
      "üü¢ Best model updated at epoch 3\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:05<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9780 Acc: 0.3204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:34<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.6168 Acc: 0.4389\n",
      "üü¢ Best model updated at epoch 4\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:05<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9937 Acc: 0.3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:32<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.6680 Acc: 0.4180\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:10<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0103 Acc: 0.3262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:32<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.6401 Acc: 0.4243\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:08<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0089 Acc: 0.3241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:32<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.6555 Acc: 0.4201\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:16<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0116 Acc: 0.3349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:32<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.6422 Acc: 0.4040\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:07<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0253 Acc: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:32<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.6327 Acc: 0.4117\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 714/714 [02:07<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0490 Acc: 0.3202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:33<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.5705 Acc: 0.4641\n",
      "üü¢ Best model updated at epoch 10\n",
      "\n",
      "‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t! Th·ªùi gian: 26m 52s\n",
      "‚úÖ Best model ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'best_model.pth'\n",
      "\n",
      "--- Final Evaluation on Best Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:32<00:00,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Best Model Validation Loss: 1.5705\n",
      "üìà Best Model Validation Accuracy: 0.4641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# --- C·∫•u h√¨nh Logging ---\n",
    "LOG_FILE = 'log_train_baseline.txt'\n",
    "with open(LOG_FILE, 'w') as log_file:\n",
    "    log_file.write('Epoch,Train Loss,Train Acc,Val Loss,Val Acc,Time\\n')\n",
    "\n",
    "# --- Bi·∫øn theo d√µi ---\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "start_time_total = time.time()\n",
    "best_val_loss = float('inf')\n",
    "best_model_wts = copy.deepcopy(model.state_dict())  # l∆∞u model t·ªët nh·∫•t\n",
    "\n",
    "# --- Hu·∫•n luy·ªán ---\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        model.train() if phase == 'train' else model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels, _ in tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Phase\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                if isinstance(outputs, tuple):  # ƒê·ªëi v·ªõi Inception v3\n",
    "                    outputs = outputs[0]\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "        print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        if phase == 'train':\n",
    "            history['train_loss'].append(epoch_loss)\n",
    "            history['train_acc'].append(epoch_acc.item())\n",
    "        else:\n",
    "            history['val_loss'].append(epoch_loss)\n",
    "            history['val_acc'].append(epoch_acc.item())\n",
    "\n",
    "            # üî• N·∫øu val_loss t·ªët h∆°n, c·∫≠p nh·∫≠t m√¥ h√¨nh t·ªët nh·∫•t\n",
    "            if epoch_loss < best_val_loss:\n",
    "                best_val_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print(f'üü¢ Best model updated at epoch {epoch+1}')\n",
    "\n",
    "    # Ghi log sau m·ªói epoch\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    with open(LOG_FILE, 'a') as log_file:\n",
    "        log_file.write(\n",
    "            f\"{epoch+1},{history['train_loss'][-1]:.4f},{history['train_acc'][-1]:.4f},\"\n",
    "            f\"{history['val_loss'][-1]:.4f},{history['val_acc'][-1]:.4f},{epoch_time:.2f}s\\n\"\n",
    "        )\n",
    "\n",
    "# --- Hu·∫•n luy·ªán ho√†n t·∫•t ---\n",
    "total_training_time = time.time() - start_time_total\n",
    "print(f'\\n‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t! Th·ªùi gian: {total_training_time // 60:.0f}m {total_training_time % 60:.0f}s')\n",
    "\n",
    "# üîÑ N·∫°p l·∫°i m√¥ h√¨nh t·ªët nh·∫•t\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "# üíæ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t ra file\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"‚úÖ Best model ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'best_model.pth'\")\n",
    "\n",
    "# --- ƒê√ÅNH GI√Å L·∫†I TR√äN M√î H√åNH T·ªêT NH·∫§T ---\n",
    "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
    "model.eval()\n",
    "final_val_loss = 0.0\n",
    "final_val_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, _ in tqdm(dataloaders['val'], desc=\"Final Evaluation\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        if isinstance(outputs, tuple):  # Cho Inception\n",
    "            outputs = outputs[0]\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        final_val_loss += loss.item() * inputs.size(0)\n",
    "        final_val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "final_loss = final_val_loss / len(dataloaders['val'].dataset)\n",
    "final_acc = final_val_corrects.double() / len(dataloaders['val'].dataset)\n",
    "\n",
    "print(f\"\\nüìä Best Model Validation Loss: {final_loss:.4f}\")\n",
    "print(f\"üìà Best Model Validation Accuracy: {final_acc:.4f}\")\n",
    "\n",
    "# Ghi k·∫øt qu·∫£ cu·ªëi v√†o log\n",
    "with open(LOG_FILE, 'a') as log_file:\n",
    "    log_file.write(\"\\n--- Final Evaluation Results (Best Model) ---\\n\")\n",
    "    log_file.write(f\"Validation Loss: {final_loss:.4f}\\n\")\n",
    "    log_file.write(f\"Validation Accuracy: {final_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706012b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [0.1, 0.01, 0.001]\n",
    "# epoch_options = [10, 20]\n",
    "# weight_decay_values = [0, 1e-4]\n",
    "\n",
    "# results_summary = []\n",
    "\n",
    "# for wd in weight_decay_values:\n",
    "#     for lr in learning_rates:\n",
    "#         for num_epochs in epoch_options:\n",
    "#             print(f\"\\n==========================\")\n",
    "#             print(f\"üîç LR = {lr}, Epochs = {num_epochs}, Weight Decay = {wd}\")\n",
    "#             print(f\"==========================\")\n",
    "\n",
    "#             # --- Kh·ªüi t·∫°o m√¥ h√¨nh ---\n",
    "#             model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "#             for param in model.parameters():\n",
    "#                 param.requires_grad = False\n",
    "#             in_feats = model.classifier[1].in_features\n",
    "#             model.classifier = nn.Sequential(\n",
    "#                 nn.Dropout(0.3),\n",
    "#                 nn.Linear(in_feats, 10)\n",
    "#             )\n",
    "#             model = model.to(device)\n",
    "\n",
    "#             # --- Loss, Optimizer, Scheduler ---\n",
    "#             criterion = nn.CrossEntropyLoss()\n",
    "#             optimizer = optim.Adam(\n",
    "#                 filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#                 lr=lr,\n",
    "#                 weight_decay=wd\n",
    "#             )\n",
    "#             scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "#             best_val_loss = float('inf')\n",
    "#             best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#             history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "#             start_time_total = time.time()\n",
    "\n",
    "#             log_file_name = f\"log_lr_{lr}_ep_{num_epochs}_wd_{wd}.txt\"\n",
    "#             with open(log_file_name, 'w') as log_file:\n",
    "#                 log_file.write('Epoch,Train Loss,Train Acc,Val Loss,Val Acc,Time\\n')\n",
    "\n",
    "#             # --- Hu·∫•n luy·ªán ---\n",
    "#             for epoch in range(num_epochs):\n",
    "#                 epoch_start_time = time.time()\n",
    "#                 print(f'\\nEpoch {epoch+1}/{num_epochs} - LR: {lr} - WD: {wd}')\n",
    "#                 print('-' * 30)\n",
    "\n",
    "#                 for phase in ['train', 'val']:\n",
    "#                     model.train() if phase == 'train' else model.eval()\n",
    "#                     running_loss = 0.0\n",
    "#                     running_corrects = 0\n",
    "\n",
    "#                     for inputs, labels, _ in tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Phase\"):\n",
    "#                         inputs = inputs.to(device)\n",
    "#                         labels = labels.to(device)\n",
    "\n",
    "#                         optimizer.zero_grad()\n",
    "#                         with torch.set_grad_enabled(phase == 'train'):\n",
    "#                             outputs = model(inputs)\n",
    "#                             if isinstance(outputs, tuple):\n",
    "#                                 outputs = outputs[0]\n",
    "#                             _, preds = torch.max(outputs, 1)\n",
    "#                             loss = criterion(outputs, labels)\n",
    "\n",
    "#                             if phase == 'train':\n",
    "#                                 loss.backward()\n",
    "#                                 optimizer.step()\n",
    "\n",
    "#                         running_loss += loss.item() * inputs.size(0)\n",
    "#                         running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#                     epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "#                     epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "#                     print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "#                     if phase == 'train':\n",
    "#                         history['train_loss'].append(epoch_loss)\n",
    "#                         history['train_acc'].append(epoch_acc.item())\n",
    "#                     else:\n",
    "#                         history['val_loss'].append(epoch_loss)\n",
    "#                         history['val_acc'].append(epoch_acc.item())\n",
    "#                         scheduler.step(epoch_loss)\n",
    "\n",
    "#                         if epoch_loss < best_val_loss:\n",
    "#                             best_val_loss = epoch_loss\n",
    "#                             best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#                             print(f'üü¢ Best model updated at epoch {epoch+1}')\n",
    "\n",
    "#                 # Ghi log epoch\n",
    "#                 epoch_time = time.time() - epoch_start_time\n",
    "#                 with open(log_file_name, 'a') as log_file:\n",
    "#                     log_file.write(\n",
    "#                         f\"{epoch+1},{history['train_loss'][-1]:.4f},{history['train_acc'][-1]:.4f},\"\n",
    "#                         f\"{history['val_loss'][-1]:.4f},{history['val_acc'][-1]:.4f},{epoch_time:.2f}s\\n\"\n",
    "#                     )\n",
    "\n",
    "#             # --- ƒê√°nh gi√° cu·ªëi ---\n",
    "#             total_training_time = time.time() - start_time_total\n",
    "#             print(f\"\\n‚úÖ Hu·∫•n luy·ªán xong. Th·ªùi gian: {total_training_time // 60:.0f}m {total_training_time % 60:.0f}s\")\n",
    "#             model.load_state_dict(best_model_wts)\n",
    "#             model_save_path = f\"best_model_lr_{lr}_ep_{num_epochs}_wd_{wd}.pth\"\n",
    "#             torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "#             # ƒê√°nh gi√° final\n",
    "#             model.eval()\n",
    "#             final_val_loss = 0.0\n",
    "#             final_val_corrects = 0\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 for inputs, labels, _ in tqdm(dataloaders['val'], desc=\"Final Evaluation\"):\n",
    "#                     inputs = inputs.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "#                     outputs = model(inputs)\n",
    "#                     if isinstance(outputs, tuple):\n",
    "#                         outputs = outputs[0]\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "#                     final_val_loss += loss.item() * inputs.size(0)\n",
    "#                     final_val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#             final_loss = final_val_loss / len(dataloaders['val'].dataset)\n",
    "#             final_acc = final_val_corrects.double() / len(dataloaders['val'].dataset)\n",
    "#             print(f\"\\nüìä Final Val Loss (LR={lr}, Epochs={num_epochs}, WD={wd}): {final_loss:.4f}\")\n",
    "#             print(f\"üìà Final Val Accuracy (LR={lr}, Epochs={num_epochs}, WD={wd}): {final_acc:.4f}\")\n",
    "\n",
    "#             results_summary.append((lr, num_epochs, wd, final_loss, final_acc.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b715e",
   "metadata": {
    "papermill": {
     "duration": 0.215519,
     "end_time": "2025-06-27T13:50:07.873340",
     "exception": false,
     "start_time": "2025-06-27T13:50:07.657821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Predict 2K**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbcf576f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:50:08.306823Z",
     "iopub.status.busy": "2025-06-27T13:50:08.306470Z",
     "iopub.status.idle": "2025-06-27T13:50:08.313146Z",
     "shell.execute_reply": "2025-06-27T13:50:08.312479Z"
    },
    "papermill": {
     "duration": 0.225107,
     "end_time": "2025-06-27T13:50:08.314259",
     "exception": false,
     "start_time": "2025-06-27T13:50:08.089152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hand-written-ditgit', 'data-10k', 'hwd-dataset']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"/kaggle/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de53398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:50:08.811703Z",
     "iopub.status.busy": "2025-06-27T13:50:08.811146Z",
     "iopub.status.idle": "2025-06-27T13:50:33.061979Z",
     "shell.execute_reply": "2025-06-27T13:50:33.061164Z"
    },
    "papermill": {
     "duration": 24.472386,
     "end_time": "2025-06-27T13:50:33.063143",
     "exception": false,
     "start_time": "2025-06-27T13:50:08.590757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng file test: 2939\n",
      "Ch·∫ø ƒë·ªô TEST. ƒêang qu√©t t·∫•t c·∫£ ·∫£nh trong '/kaggle/input/hand-written-ditgit'...\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "ƒê√£ t√¨m th·∫•y 2928 file ·ª©ng vi√™n. B·∫Øt ƒë·∫ßu x√°c th·ª±c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x√°c th·ª±c file: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2928/2928 [00:24<00:00, 121.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ho√†n th√†nh qu√©t v√† x√°c th·ª±c ---\n",
      "T·ªïng s·ªë ·∫£nh h·ª£p l·ªá c√≥ th·ªÉ s·ª≠ d·ª•ng: 2928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/kaggle/input/hand-written-ditgit'\n",
    "test_list = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
    "\n",
    "print(f\"S·ªë l∆∞·ª£ng file test: {len(test_list)}\")\n",
    "\n",
    "test_dataset = custom_image_dataset(test_dir, transform = data_transforms['val'], test=True )\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "791e3127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:50:33.549580Z",
     "iopub.status.busy": "2025-06-27T13:50:33.548809Z",
     "iopub.status.idle": "2025-06-27T13:51:20.369098Z",
     "shell.execute_reply": "2025-06-27T13:51:20.367965Z"
    },
    "papermill": {
     "duration": 47.078785,
     "end_time": "2025-06-27T13:51:20.370338",
     "exception": false,
     "start_time": "2025-06-27T13:50:33.291553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang d·ª± ƒëo√°n:.....: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:46<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in 'predict_2k.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_txt = \"\"\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc=\"ƒêang d·ª± ƒëo√°n:.....\"):\n",
    "        images, labels, paths = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # save\n",
    "        for path, pred in zip(paths, predicted):\n",
    "            path = path.replace(test_dir, \"\").lstrip(os.sep)  \n",
    "            predict_txt += f\"{path},{pred.item()}\\n\"\n",
    "\n",
    "# Write to file in text mode\n",
    "with open(\"/kaggle/working/predict_2k.txt\", \"w\") as file:\n",
    "    file.write(predict_txt)\n",
    "print(\"Predictions saved in 'predict_2k.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e808da",
   "metadata": {
    "papermill": {
     "duration": 0.234169,
     "end_time": "2025-06-27T13:51:20.888876",
     "exception": false,
     "start_time": "2025-06-27T13:51:20.654707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Predict 10k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd738c87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:51:21.355490Z",
     "iopub.status.busy": "2025-06-27T13:51:21.355200Z",
     "iopub.status.idle": "2025-06-27T13:52:49.676169Z",
     "shell.execute_reply": "2025-06-27T13:52:49.675384Z"
    },
    "papermill": {
     "duration": 88.557874,
     "end_time": "2025-06-27T13:52:49.677481",
     "exception": false,
     "start_time": "2025-06-27T13:51:21.119607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng file test: 9998\n",
      "Ch·∫ø ƒë·ªô TEST. ƒêang qu√©t t·∫•t c·∫£ ·∫£nh trong '/kaggle/input/data-10k'...\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "ƒê√£ t√¨m th·∫•y 9987 file ·ª©ng vi√™n. B·∫Øt ƒë·∫ßu x√°c th·ª±c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang x√°c th·ª±c file: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9987/9987 [01:27<00:00, 113.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ho√†n th√†nh qu√©t v√† x√°c th·ª±c ---\n",
      "T·ªïng s·ªë ·∫£nh h·ª£p l·ªá c√≥ th·ªÉ s·ª≠ d·ª•ng: 9975\n",
      "ƒê√£ ph√°t hi·ªán v√† lo·∫°i b·ªè 12 file b·ªã l·ªói.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/kaggle/input/data-10k'\n",
    "test_list = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
    "\n",
    "print(f\"S·ªë l∆∞·ª£ng file test: {len(test_list)}\")\n",
    "\n",
    "test_dataset = custom_image_dataset(test_dir, transform = data_transforms['val'], test=True )\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ca6ab9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:52:50.206829Z",
     "iopub.status.busy": "2025-06-27T13:52:50.206560Z",
     "iopub.status.idle": "2025-06-27T13:56:09.613991Z",
     "shell.execute_reply": "2025-06-27T13:56:09.613089Z"
    },
    "papermill": {
     "duration": 199.671132,
     "end_time": "2025-06-27T13:56:09.615093",
     "exception": false,
     "start_time": "2025-06-27T13:52:49.943961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang d·ª± ƒëo√°n:.....: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1247/1247 [03:19<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in 'predict_10k.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_txt = \"\"\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc=\"ƒêang d·ª± ƒëo√°n:.....\"):\n",
    "        images, labels, paths = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # save\n",
    "        for path, pred in zip(paths, predicted):\n",
    "            path = path.replace(test_dir, \"\").lstrip(os.sep)  \n",
    "            predict_txt += f\"{path},{pred.item()}\\n\"\n",
    "\n",
    "# Write to file in text mode\n",
    "with open(\"/kaggle/working/predict_10k.txt\", \"w\") as file:\n",
    "    file.write(predict_txt)\n",
    "print(\"Predictions saved in 'predict_10k.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35684ea1",
   "metadata": {
    "papermill": {
     "duration": 0.288413,
     "end_time": "2025-06-27T13:56:10.247676",
     "exception": false,
     "start_time": "2025-06-27T13:56:09.959263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7607145,
     "sourceId": 12084322,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7619198,
     "sourceId": 12102611,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7740132,
     "sourceId": 12281807,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2078.386479,
   "end_time": "2025-06-27T13:56:13.916141",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-27T13:21:35.529662",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
