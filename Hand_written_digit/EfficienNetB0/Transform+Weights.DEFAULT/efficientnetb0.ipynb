{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68cea8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:11:46.164962Z",
     "iopub.status.busy": "2025-06-27T08:11:46.164762Z",
     "iopub.status.idle": "2025-06-27T08:11:57.480649Z",
     "shell.execute_reply": "2025-06-27T08:11:57.479857Z"
    },
    "papermill": {
     "duration": 11.322091,
     "end_time": "2025-06-27T08:11:57.482090",
     "exception": false,
     "start_time": "2025-06-27T08:11:46.159999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7d2ab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:11:57.490707Z",
     "iopub.status.busy": "2025-06-27T08:11:57.490118Z",
     "iopub.status.idle": "2025-06-27T08:11:57.577683Z",
     "shell.execute_reply": "2025-06-27T08:11:57.577051Z"
    },
    "papermill": {
     "duration": 0.092895,
     "end_time": "2025-06-27T08:11:57.578794",
     "exception": false,
     "start_time": "2025-06-27T08:11:57.485899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Đường dẫn đến dataset\n",
    "DATASET_PATH = '/kaggle/input/hwd-dataset/digits_data_final'\n",
    "TRAIN_DIR = os.path.join(DATASET_PATH, 'train')\n",
    "VAL_DIR = os.path.join(DATASET_PATH, 'val')\n",
    "\n",
    "# Tham số\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 10 \n",
    "EPOCHS = 10\n",
    "num_workers = os.cpu_count()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5f17d",
   "metadata": {
    "papermill": {
     "duration": 0.00291,
     "end_time": "2025-06-27T08:11:57.585138",
     "exception": false,
     "start_time": "2025-06-27T08:11:57.582228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a94c18a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:11:57.591800Z",
     "iopub.status.busy": "2025-06-27T08:11:57.591570Z",
     "iopub.status.idle": "2025-06-27T08:12:00.180725Z",
     "shell.execute_reply": "2025-06-27T08:12:00.179970Z"
    },
    "papermill": {
     "duration": 2.594004,
     "end_time": "2025-06-27T08:12:00.182061",
     "exception": false,
     "start_time": "2025-06-27T08:11:57.588057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pillow-hief (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pillow-hief\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pillow-hief -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2aefdb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:12:00.189628Z",
     "iopub.status.busy": "2025-06-27T08:12:00.189388Z",
     "iopub.status.idle": "2025-06-27T08:12:00.591181Z",
     "shell.execute_reply": "2025-06-27T08:12:00.590353Z"
    },
    "papermill": {
     "duration": 0.406903,
     "end_time": "2025-06-27T08:12:00.592391",
     "exception": false,
     "start_time": "2025-06-27T08:12:00.185488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số ảnh trong TRAIN: 5712\n",
      "Tổng số ảnh trong VAL: 1433\n"
     ]
    }
   ],
   "source": [
    "def count_images_in_folder(folder_path):\n",
    "    total = 0\n",
    "    class_folders = glob.glob(os.path.join(folder_path, \"*/\"))\n",
    "    for class_path in class_folders:\n",
    "        image_files = glob.glob(os.path.join(class_path, \"*\"))\n",
    "        total += len(image_files)\n",
    "    return total\n",
    "\n",
    "# Tổng số ảnh trong train\n",
    "total_train = count_images_in_folder(f\"{DATASET_PATH}/train\")\n",
    "print(f\"Tổng số ảnh trong TRAIN: {total_train}\")\n",
    "\n",
    "# Tổng số ảnh trong val\n",
    "total_val = count_images_in_folder(f\"{DATASET_PATH}/val\")\n",
    "print(f\"Tổng số ảnh trong VAL: {total_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af3a532",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:12:00.599740Z",
     "iopub.status.busy": "2025-06-27T08:12:00.599519Z",
     "iopub.status.idle": "2025-06-27T08:12:04.262438Z",
     "shell.execute_reply": "2025-06-27T08:12:04.261430Z"
    },
    "papermill": {
     "duration": 3.668174,
     "end_time": "2025-06-27T08:12:04.263893",
     "exception": false,
     "start_time": "2025-06-27T08:12:00.595719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow_heif\r\n",
      "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\r\n",
      "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.11/dist-packages (from pillow_heif) (11.1.0)\r\n",
      "Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pillow_heif\r\n",
      "Successfully installed pillow_heif-0.22.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow_heif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e20fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:12:04.272648Z",
     "iopub.status.busy": "2025-06-27T08:12:04.272396Z",
     "iopub.status.idle": "2025-06-27T08:12:04.297228Z",
     "shell.execute_reply": "2025-06-27T08:12:04.296531Z"
    },
    "papermill": {
     "duration": 0.030528,
     "end_time": "2025-06-27T08:12:04.298278",
     "exception": false,
     "start_time": "2025-06-27T08:12:04.267750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pillow_heif import register_heif_opener\n",
    "\n",
    "class custom_image_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Một Dataset tùy chỉnh đa năng cho cả train/val và test.\n",
    "\n",
    "    - Nếu test=False: Quét các thư mục con làm nhãn.\n",
    "    - Nếu test=True: Quét tất cả ảnh trong thư mục gốc và gán nhãn là -1.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None, test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "        # SỬA LỖI 2: Thống nhất dùng tên self.image_paths\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        if not os.path.isdir(root_dir):\n",
    "            raise ValueError(f\"Đường dẫn không tồn tại: {root_dir}\")\n",
    "\n",
    "        candidate_files = []\n",
    "        if not self.test:\n",
    "            # --- Chế độ TRAIN/VAL ---\n",
    "            class_names = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "            class_to_idx = {cls_name: i for i, cls_name in enumerate(class_names)}\n",
    "            print(f\"Chế độ TRAIN/VAL. Đã tìm thấy các lớp: {class_names} tại '{root_dir}'\")\n",
    "\n",
    "            for class_name in class_names:\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                label = class_to_idx[class_name]\n",
    "                for filename in os.listdir(class_dir):\n",
    "                    if filename.lower().endswith('.md'):\n",
    "                        print('Found MarkDown')\n",
    "                        pass\n",
    "                    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.heic', '.heif', '.jfif')):\n",
    "                        candidate_files.append((os.path.join(class_dir, filename), label))\n",
    "        else:\n",
    "            # --- Chế độ TEST ---\n",
    "            print(f\"Chế độ TEST. Đang quét tất cả ảnh trong '{root_dir}'...\")\n",
    "            for filename in os.listdir(root_dir):\n",
    "                if filename.lower().endswith('.md'):\n",
    "                        print('Found MarkDown')\n",
    "                        pass\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.heic', '.heif', '.jfif')):\n",
    "                    # SỬA LỖI 1: Dùng root_dir thay vì class_dir\n",
    "                    full_path = os.path.join(root_dir, filename)\n",
    "                    candidate_files.append((full_path, -1))\n",
    "\n",
    "        # Xác thực các file ứng viên\n",
    "        print(f\"Đã tìm thấy {len(candidate_files)} file ứng viên. Bắt đầu xác thực...\")\n",
    "        corrupted_files = []\n",
    "        for img_path, label in tqdm(candidate_files, desc=\"Đang xác thực file\"):\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img.verify()\n",
    "                # Nếu file hợp lệ, thêm vào danh sách cuối cùng\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(label)\n",
    "            except Exception:\n",
    "                corrupted_files.append(img_path)\n",
    "        \n",
    "        print(\"\\n--- Hoàn thành quét và xác thực ---\")\n",
    "        print(f\"Tổng số ảnh hợp lệ có thể sử dụng: {len(self.image_paths)}\")\n",
    "        if corrupted_files:\n",
    "            print(f\"Đã phát hiện và loại bỏ {len(corrupted_files)} file bị lỗi.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # SỬA LỖI 2: Dùng đúng tên biến\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6de5f6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:12:04.305842Z",
     "iopub.status.busy": "2025-06-27T08:12:04.305640Z",
     "iopub.status.idle": "2025-06-27T08:12:04.308774Z",
     "shell.execute_reply": "2025-06-27T08:12:04.308248Z"
    },
    "papermill": {
     "duration": 0.008025,
     "end_time": "2025-06-27T08:12:04.309734",
     "exception": false,
     "start_time": "2025-06-27T08:12:04.301709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_heif_opener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d021a529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:12:04.317116Z",
     "iopub.status.busy": "2025-06-27T08:12:04.316920Z",
     "iopub.status.idle": "2025-06-27T08:13:38.746070Z",
     "shell.execute_reply": "2025-06-27T08:13:38.745231Z"
    },
    "papermill": {
     "duration": 94.434295,
     "end_time": "2025-06-27T08:13:38.747367",
     "exception": false,
     "start_time": "2025-06-27T08:12:04.313072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chế độ TRAIN/VAL. Đã tìm thấy các lớp: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] tại '/kaggle/input/hwd-dataset/digits_data_final/train'\n",
      "Đã tìm thấy 5712 file ứng viên. Bắt đầu xác thực...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang xác thực file: 100%|██████████| 5712/5712 [01:09<00:00, 82.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hoàn thành quét và xác thực ---\n",
      "Tổng số ảnh hợp lệ có thể sử dụng: 5712\n",
      "Chế độ TRAIN/VAL. Đã tìm thấy các lớp: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] tại '/kaggle/input/hwd-dataset/digits_data_final/val'\n",
      "Đã tìm thấy 1433 file ứng viên. Bắt đầu xác thực...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang xác thực file: 100%|██████████| 1433/1433 [00:24<00:00, 57.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hoàn thành quét và xác thực ---\n",
      "Tổng số ảnh hợp lệ có thể sử dụng: 1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Định nghĩa các phép biến đổi cho dữ liệu\n",
    "# Rất quan trọng: phải chuẩn hóa giống như khi pre-train mô hình\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Lambda(lambda img: img.convert('RGB')),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Lambda(lambda img: img.convert('RGB')),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "try:\n",
    "    image_datasets = {\n",
    "    'train': custom_image_dataset(TRAIN_DIR, transform=data_transforms['train']),\n",
    "    'val': custom_image_dataset(VAL_DIR, transform=data_transforms['val'])\n",
    "}\n",
    "\n",
    "\n",
    "    dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, shuffle=True, num_workers=2),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "}\n",
    "\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(f\"Đã xảy ra lỗi không mong muốn: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "319aaac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:13:38.815192Z",
     "iopub.status.busy": "2025-06-27T08:13:38.814964Z",
     "iopub.status.idle": "2025-06-27T08:13:39.584499Z",
     "shell.execute_reply": "2025-06-27T08:13:39.583642Z"
    },
    "papermill": {
     "duration": 0.804105,
     "end_time": "2025-06-27T08:13:39.585798",
     "exception": false,
     "start_time": "2025-06-27T08:13:38.781693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|██████████| 20.5M/20.5M [00:00<00:00, 113MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.3, inplace=False)\n",
      "  (1): Linear(in_features=1280, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.efficientnet_b0(weights=\"EfficientNet_B0_Weights.DEFAULT\")\n",
    "\n",
    "# Đóng băng tất cả các tham số của mô hình\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.efficientnet_b0(weights=\"EfficientNet_B0_Weights.DEFAULT\")\n",
    "in_feats = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(in_feats, 10)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# In ra cấu trúc classifier mới\n",
    "print(model.classifier)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tổng số tham số\n",
    "# total_params = sum(p.numel() for p in model.parameters())\n",
    "# # Số tham số huấn luyện được\n",
    "# trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# print(total_params)\n",
    "# print(trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce7e6e8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:13:39.654244Z",
     "iopub.status.busy": "2025-06-27T08:13:39.654017Z",
     "iopub.status.idle": "2025-06-27T08:41:08.394681Z",
     "shell.execute_reply": "2025-06-27T08:41:08.393374Z"
    },
    "papermill": {
     "duration": 1648.776316,
     "end_time": "2025-06-27T08:41:08.395994",
     "exception": false,
     "start_time": "2025-06-27T08:13:39.619678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 714/714 [02:14<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9729 Acc: 0.6901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 180/180 [00:32<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3681 Acc: 0.9016\n",
      "🟢 Best model updated at epoch 1\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 714/714 [02:12<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4522 Acc: 0.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 180/180 [00:30<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2907 Acc: 0.9191\n",
      "🟢 Best model updated at epoch 2\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 714/714 [02:10<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3552 Acc: 0.9013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 180/180 [00:30<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2397 Acc: 0.9372\n",
      "🟢 Best model updated at epoch 3\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 714/714 [02:08<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2890 Acc: 0.9149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 180/180 [00:31<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1704 Acc: 0.9546\n",
      "🟢 Best model updated at epoch 4\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 714/714 [02:08<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2414 Acc: 0.9312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 180/180 [00:31<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1718 Acc: 0.9505\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 714/714 [02:09<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2241 Acc: 0.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 180/180 [00:31<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2462 Acc: 0.9330\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 714/714 [02:11<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2103 Acc: 0.9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 180/180 [00:31<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1486 Acc: 0.9505\n",
      "🟢 Best model updated at epoch 7\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 714/714 [02:08<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1963 Acc: 0.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 180/180 [00:31<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1467 Acc: 0.9560\n",
      "🟢 Best model updated at epoch 8\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 714/714 [02:11<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1576 Acc: 0.9534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 180/180 [00:30<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1925 Acc: 0.9518\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 714/714 [02:10<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1752 Acc: 0.9496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 180/180 [00:31<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1278 Acc: 0.9644\n",
      "🟢 Best model updated at epoch 10\n",
      "\n",
      "✅ Huấn luyện hoàn tất! Thời gian: 26m 57s\n",
      "✅ Best model đã được lưu vào 'best_model.pth'\n",
      "\n",
      "--- Final Evaluation on Best Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Evaluation: 100%|██████████| 180/180 [00:31<00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Best Model Validation Loss: 0.1278\n",
      "📈 Best Model Validation Accuracy: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# --- Cấu hình Logging ---\n",
    "LOG_FILE = 'log_train_baseline.txt'\n",
    "with open(LOG_FILE, 'w') as log_file:\n",
    "    log_file.write('Epoch,Train Loss,Train Acc,Val Loss,Val Acc,Time\\n')\n",
    "\n",
    "# --- Biến theo dõi ---\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "start_time_total = time.time()\n",
    "best_val_loss = float('inf')\n",
    "best_model_wts = copy.deepcopy(model.state_dict())  # lưu model tốt nhất\n",
    "\n",
    "# --- Huấn luyện ---\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        model.train() if phase == 'train' else model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels, _ in tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Phase\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                if isinstance(outputs, tuple):  # Đối với Inception v3\n",
    "                    outputs = outputs[0]\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "        print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        if phase == 'train':\n",
    "            history['train_loss'].append(epoch_loss)\n",
    "            history['train_acc'].append(epoch_acc.item())\n",
    "        else:\n",
    "            history['val_loss'].append(epoch_loss)\n",
    "            history['val_acc'].append(epoch_acc.item())\n",
    "\n",
    "            # 🔥 Nếu val_loss tốt hơn, cập nhật mô hình tốt nhất\n",
    "            if epoch_loss < best_val_loss:\n",
    "                best_val_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print(f'🟢 Best model updated at epoch {epoch+1}')\n",
    "\n",
    "    # Ghi log sau mỗi epoch\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    with open(LOG_FILE, 'a') as log_file:\n",
    "        log_file.write(\n",
    "            f\"{epoch+1},{history['train_loss'][-1]:.4f},{history['train_acc'][-1]:.4f},\"\n",
    "            f\"{history['val_loss'][-1]:.4f},{history['val_acc'][-1]:.4f},{epoch_time:.2f}s\\n\"\n",
    "        )\n",
    "\n",
    "# --- Huấn luyện hoàn tất ---\n",
    "total_training_time = time.time() - start_time_total\n",
    "print(f'\\n✅ Huấn luyện hoàn tất! Thời gian: {total_training_time // 60:.0f}m {total_training_time % 60:.0f}s')\n",
    "\n",
    "# 🔄 Nạp lại mô hình tốt nhất\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "# 💾 Lưu mô hình tốt nhất ra file\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"✅ Best model đã được lưu vào 'best_model.pth'\")\n",
    "\n",
    "# --- ĐÁNH GIÁ LẠI TRÊN MÔ HÌNH TỐT NHẤT ---\n",
    "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
    "model.eval()\n",
    "final_val_loss = 0.0\n",
    "final_val_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, _ in tqdm(dataloaders['val'], desc=\"Final Evaluation\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        if isinstance(outputs, tuple):  # Cho Inception\n",
    "            outputs = outputs[0]\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        final_val_loss += loss.item() * inputs.size(0)\n",
    "        final_val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "final_loss = final_val_loss / len(dataloaders['val'].dataset)\n",
    "final_acc = final_val_corrects.double() / len(dataloaders['val'].dataset)\n",
    "\n",
    "print(f\"\\n📊 Best Model Validation Loss: {final_loss:.4f}\")\n",
    "print(f\"📈 Best Model Validation Accuracy: {final_acc:.4f}\")\n",
    "\n",
    "# Ghi kết quả cuối vào log\n",
    "with open(LOG_FILE, 'a') as log_file:\n",
    "    log_file.write(\"\\n--- Final Evaluation Results (Best Model) ---\\n\")\n",
    "    log_file.write(f\"Validation Loss: {final_loss:.4f}\\n\")\n",
    "    log_file.write(f\"Validation Accuracy: {final_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [0.1, 0.01, 0.001]\n",
    "# epoch_options = [10, 20]\n",
    "# weight_decay_values = [0, 1e-4]\n",
    "\n",
    "# results_summary = []\n",
    "\n",
    "# for wd in weight_decay_values:\n",
    "#     for lr in learning_rates:\n",
    "#         for num_epochs in epoch_options:\n",
    "#             print(f\"\\n==========================\")\n",
    "#             print(f\"🔍 LR = {lr}, Epochs = {num_epochs}, Weight Decay = {wd}\")\n",
    "#             print(f\"==========================\")\n",
    "\n",
    "#             # --- Khởi tạo mô hình ---\n",
    "#             model = models.efficientnet_b0(weights=\"EfficientNet_B0_Weights.DEFAULT\")\n",
    "#             for param in model.parameters():\n",
    "#                 param.requires_grad = False\n",
    "#             in_feats = model.classifier[1].in_features\n",
    "#             model.classifier = nn.Sequential(\n",
    "#                 nn.Dropout(0.3),\n",
    "#                 nn.Linear(in_feats, 10)\n",
    "#             )\n",
    "#             model = model.to(device)\n",
    "\n",
    "#             # --- Loss, Optimizer, Scheduler ---\n",
    "#             criterion = nn.CrossEntropyLoss()\n",
    "#             optimizer = optim.Adam(\n",
    "#                 filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#                 lr=lr,\n",
    "#                 weight_decay=wd\n",
    "#             )\n",
    "#             scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "#             best_val_loss = float('inf')\n",
    "#             best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#             history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "#             start_time_total = time.time()\n",
    "\n",
    "#             log_file_name = f\"log_lr_{lr}_ep_{num_epochs}_wd_{wd}.txt\"\n",
    "#             with open(log_file_name, 'w') as log_file:\n",
    "#                 log_file.write('Epoch,Train Loss,Train Acc,Val Loss,Val Acc,Time\\n')\n",
    "\n",
    "#             # --- Huấn luyện ---\n",
    "#             for epoch in range(num_epochs):\n",
    "#                 epoch_start_time = time.time()\n",
    "#                 print(f'\\nEpoch {epoch+1}/{num_epochs} - LR: {lr} - WD: {wd}')\n",
    "#                 print('-' * 30)\n",
    "\n",
    "#                 for phase in ['train', 'val']:\n",
    "#                     model.train() if phase == 'train' else model.eval()\n",
    "#                     running_loss = 0.0\n",
    "#                     running_corrects = 0\n",
    "\n",
    "#                     for inputs, labels, _ in tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Phase\"):\n",
    "#                         inputs = inputs.to(device)\n",
    "#                         labels = labels.to(device)\n",
    "\n",
    "#                         optimizer.zero_grad()\n",
    "#                         with torch.set_grad_enabled(phase == 'train'):\n",
    "#                             outputs = model(inputs)\n",
    "#                             if isinstance(outputs, tuple):\n",
    "#                                 outputs = outputs[0]\n",
    "#                             _, preds = torch.max(outputs, 1)\n",
    "#                             loss = criterion(outputs, labels)\n",
    "\n",
    "#                             if phase == 'train':\n",
    "#                                 loss.backward()\n",
    "#                                 optimizer.step()\n",
    "\n",
    "#                         running_loss += loss.item() * inputs.size(0)\n",
    "#                         running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#                     epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "#                     epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "#                     print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "#                     if phase == 'train':\n",
    "#                         history['train_loss'].append(epoch_loss)\n",
    "#                         history['train_acc'].append(epoch_acc.item())\n",
    "#                     else:\n",
    "#                         history['val_loss'].append(epoch_loss)\n",
    "#                         history['val_acc'].append(epoch_acc.item())\n",
    "#                         scheduler.step(epoch_loss)\n",
    "\n",
    "#                         if epoch_loss < best_val_loss:\n",
    "#                             best_val_loss = epoch_loss\n",
    "#                             best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#                             print(f'🟢 Best model updated at epoch {epoch+1}')\n",
    "\n",
    "#                 # Ghi log epoch\n",
    "#                 epoch_time = time.time() - epoch_start_time\n",
    "#                 with open(log_file_name, 'a') as log_file:\n",
    "#                     log_file.write(\n",
    "#                         f\"{epoch+1},{history['train_loss'][-1]:.4f},{history['train_acc'][-1]:.4f},\"\n",
    "#                         f\"{history['val_loss'][-1]:.4f},{history['val_acc'][-1]:.4f},{epoch_time:.2f}s\\n\"\n",
    "#                     )\n",
    "\n",
    "#             # --- Đánh giá cuối ---\n",
    "#             total_training_time = time.time() - start_time_total\n",
    "#             print(f\"\\n✅ Huấn luyện xong. Thời gian: {total_training_time // 60:.0f}m {total_training_time % 60:.0f}s\")\n",
    "#             model.load_state_dict(best_model_wts)\n",
    "#             model_save_path = f\"best_model_lr_{lr}_ep_{num_epochs}_wd_{wd}.pth\"\n",
    "#             torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "#             # Đánh giá final\n",
    "#             model.eval()\n",
    "#             final_val_loss = 0.0\n",
    "#             final_val_corrects = 0\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 for inputs, labels, _ in tqdm(dataloaders['val'], desc=\"Final Evaluation\"):\n",
    "#                     inputs = inputs.to(device)\n",
    "#                     labels = labels.to(device)\n",
    "#                     outputs = model(inputs)\n",
    "#                     if isinstance(outputs, tuple):\n",
    "#                         outputs = outputs[0]\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "#                     final_val_loss += loss.item() * inputs.size(0)\n",
    "#                     final_val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#             final_loss = final_val_loss / len(dataloaders['val'].dataset)\n",
    "#             final_acc = final_val_corrects.double() / len(dataloaders['val'].dataset)\n",
    "#             print(f\"\\n📊 Final Val Loss (LR={lr}, Epochs={num_epochs}, WD={wd}): {final_loss:.4f}\")\n",
    "#             print(f\"📈 Final Val Accuracy (LR={lr}, Epochs={num_epochs}, WD={wd}): {final_acc:.4f}\")\n",
    "\n",
    "#             results_summary.append((lr, num_epochs, wd, final_loss, final_acc.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec0ae8",
   "metadata": {
    "papermill": {
     "duration": 0.231975,
     "end_time": "2025-06-27T08:41:08.863170",
     "exception": false,
     "start_time": "2025-06-27T08:41:08.631195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Predict 2K**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e475e1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:41:09.374665Z",
     "iopub.status.busy": "2025-06-27T08:41:09.373996Z",
     "iopub.status.idle": "2025-06-27T08:41:09.380646Z",
     "shell.execute_reply": "2025-06-27T08:41:09.380165Z"
    },
    "papermill": {
     "duration": 0.28702,
     "end_time": "2025-06-27T08:41:09.381777",
     "exception": false,
     "start_time": "2025-06-27T08:41:09.094757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hand-written-ditgit', 'hwd-dataset', 'data-10k']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"/kaggle/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11fe79fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:41:09.849046Z",
     "iopub.status.busy": "2025-06-27T08:41:09.848236Z",
     "iopub.status.idle": "2025-06-27T08:41:38.033725Z",
     "shell.execute_reply": "2025-06-27T08:41:38.033002Z"
    },
    "papermill": {
     "duration": 28.419405,
     "end_time": "2025-06-27T08:41:38.034959",
     "exception": false,
     "start_time": "2025-06-27T08:41:09.615554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng file test: 2939\n",
      "Chế độ TEST. Đang quét tất cả ảnh trong '/kaggle/input/hand-written-ditgit'...\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Đã tìm thấy 2928 file ứng viên. Bắt đầu xác thực...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang xác thực file: 100%|██████████| 2928/2928 [00:27<00:00, 104.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hoàn thành quét và xác thực ---\n",
      "Tổng số ảnh hợp lệ có thể sử dụng: 2928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/kaggle/input/hand-written-ditgit'\n",
    "test_list = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
    "\n",
    "print(f\"Số lượng file test: {len(test_list)}\")\n",
    "\n",
    "test_dataset = custom_image_dataset(test_dir, transform = data_transforms['val'], test=True )\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c38fe1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:41:38.518789Z",
     "iopub.status.busy": "2025-06-27T08:41:38.517981Z",
     "iopub.status.idle": "2025-06-27T08:42:19.927394Z",
     "shell.execute_reply": "2025-06-27T08:42:19.926451Z"
    },
    "papermill": {
     "duration": 41.651213,
     "end_time": "2025-06-27T08:42:19.928697",
     "exception": false,
     "start_time": "2025-06-27T08:41:38.277484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang dự đoán:.....: 100%|██████████| 366/366 [00:41<00:00,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in 'predict_2k.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_txt = \"\"\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc=\"Đang dự đoán:.....\"):\n",
    "        images, labels, paths = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # save\n",
    "        for path, pred in zip(paths, predicted):\n",
    "            path = path.replace(test_dir, \"\").lstrip(os.sep)  \n",
    "            predict_txt += f\"{path},{pred.item()}\\n\"\n",
    "\n",
    "# Write to file in text mode\n",
    "with open(\"/kaggle/working/predict_2k.txt\", \"w\") as file:\n",
    "    file.write(predict_txt)\n",
    "print(\"Predictions saved in 'predict_2k.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7657e54a",
   "metadata": {
    "papermill": {
     "duration": 0.244765,
     "end_time": "2025-06-27T08:42:20.423426",
     "exception": false,
     "start_time": "2025-06-27T08:42:20.178661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Predict 10k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b0fe8e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:42:20.968780Z",
     "iopub.status.busy": "2025-06-27T08:42:20.968012Z",
     "iopub.status.idle": "2025-06-27T08:44:03.348073Z",
     "shell.execute_reply": "2025-06-27T08:44:03.347300Z"
    },
    "papermill": {
     "duration": 102.630024,
     "end_time": "2025-06-27T08:44:03.349376",
     "exception": false,
     "start_time": "2025-06-27T08:42:20.719352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng file test: 9998\n",
      "Chế độ TEST. Đang quét tất cả ảnh trong '/kaggle/input/data-10k'...\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Found MarkDown\n",
      "Đã tìm thấy 9987 file ứng viên. Bắt đầu xác thực...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang xác thực file: 100%|██████████| 9987/9987 [01:41<00:00, 98.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hoàn thành quét và xác thực ---\n",
      "Tổng số ảnh hợp lệ có thể sử dụng: 9975\n",
      "Đã phát hiện và loại bỏ 12 file bị lỗi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/kaggle/input/data-10k'\n",
    "test_list = [os.path.join(test_dir, img) for img in os.listdir(test_dir)]\n",
    "\n",
    "print(f\"Số lượng file test: {len(test_list)}\")\n",
    "\n",
    "test_dataset = custom_image_dataset(test_dir, transform = data_transforms['val'], test=True )\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7360fcee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T08:44:03.967898Z",
     "iopub.status.busy": "2025-06-27T08:44:03.967608Z",
     "iopub.status.idle": "2025-06-27T08:47:12.137877Z",
     "shell.execute_reply": "2025-06-27T08:47:12.136759Z"
    },
    "papermill": {
     "duration": 188.451962,
     "end_time": "2025-06-27T08:47:12.139183",
     "exception": false,
     "start_time": "2025-06-27T08:44:03.687221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang dự đoán:.....: 100%|██████████| 1247/1247 [03:08<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in 'predict_10k.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_txt = \"\"\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc=\"Đang dự đoán:.....\"):\n",
    "        images, labels, paths = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # save\n",
    "        for path, pred in zip(paths, predicted):\n",
    "            path = path.replace(test_dir, \"\").lstrip(os.sep)  \n",
    "            predict_txt += f\"{path},{pred.item()}\\n\"\n",
    "\n",
    "# Write to file in text mode\n",
    "with open(\"/kaggle/working/predict_10k.txt\", \"w\") as file:\n",
    "    file.write(predict_txt)\n",
    "print(\"Predictions saved in 'predict_10k.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b11629d",
   "metadata": {
    "papermill": {
     "duration": 0.307243,
     "end_time": "2025-06-27T08:47:12.754008",
     "exception": false,
     "start_time": "2025-06-27T08:47:12.446765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7607145,
     "sourceId": 12084322,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7619198,
     "sourceId": 12102611,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7740132,
     "sourceId": 12281807,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2134.707666,
   "end_time": "2025-06-27T08:47:16.322120",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-27T08:11:41.614454",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
